---
title: "Data Cleaning"
format: html
---

```{r}
#| message: false  

# Libraries
library(tidyverse)

# file names
datadir_raw <- "data/raw/"

datadir_processed <- "data/processed/"

species_file <- "ASDN_Daily_species.csv"

snowsurvey_file <- "ASDN_Snow_survey.csv"
```


## Snow survey data

### Data Exploration

Import the snow survey

```{r}
# Import the species
snowsurvey_csv <- read_csv(file.path(datadir_raw, snowsurvey_file))

glimpse(snowsurvey_csv)

```

Ok, the types are not what we were expecting for the percentages of cover. Let's find out why:

```{r}

```

Let's focus on the non-numeric values as a starting point:

```{r}

```

### Data cleaning

Ok, we found our problematic values that are not numeric. There are a non-negligible number of cells with a dot as value. There is no mention of using this symbol in the metadata. We should probably have a look at those rows:

```{r}

```

Interestingly, when there is a "dot" for snow cover, it is also the case for all the other covers. Let's replace them all with NA since there is no supplemental information in the provided metadata

```{r}

```

We will now tackle the other problematic values:

The problem is similar with "-", let's set it to NA

```{r}

```

"n/a" is pretty clear regarding how to fix it:

```{r}

```

"unk" is probably an abbreviation for unknown:

```{r}

```

Finally we will set "<1" as zero (quite arbitrary indeed):

```{r}

```

Now we can test if we now only have NAs as non numeric values in the column:

```{r}

```

Ok, we can do the transformation:

```{r}

```

Yeah we have finally a numeric column ðŸŽ‰. Now we can verify that all the values are between 0 and 100:

```{r}
 
```

We have two values above 100, with an interesting 470%! â˜ƒï¸ We should probably set those values to NAs:

```{r}

```

Let's check for negative values:

```{r}

```

No negative value detected âœ…

Let's write the presence table to a csv file:

```{r}
write_csv(snowsurvey_fixed, file.path(datadir_processed, "snow_cover.csv"))
```

<hr> 


## Species data

### Data exploration

Import the species csv files with the bird species information:

```{r}

```

This data set is stored in a wide format where each specie has its own column. This means that every time we discover a new species we will have to add a column. In addition, a bunch of `0` are stored in this table but do not really provide any information. According to the metadata:

```
The number of individuals seen is recorded for each species, except when individuals were not counted but the species was present (typically for very abundant species), an "X" is shown. The remaining columns list the full-name of species (birds and mammals) recorded for at least study site in at least one year.
```

This data model is not convenient for a database, we will have to switch to a long format.


### Data cleaning

```{r}

```


```{r}

```

We want to focus on the presence and absence of species and not the count. Let's create a new column for presence where anything else than 0 is considered present

```{r}

```

We can remove some columns: "Num_observers", "All_obs_reported", "Observer_hours" are here to help to compute the effort of observation but since we just want presence and absence, we do not need it. We can also remove all the zeros values to reduce the size of our data set:

```{r}

```

Last but not least, let's have a look at our species list

```{r}

```

We have 319 species observed in this table. The "convention" seems to be that `_` are used to separate the different parts of a name. Note that it is not clear what type of nomenclature reference is used to pull those names from.

Let's write the presence table to a csv file:

```{r}
write_csv(species_presence, file.path(datadir_processed, "species_presence.csv"))
```



