---
title: "Data Cleaning Assignment"
author: "Tom Gibbens-Matsuyama"
format: html
editor: visual
---

### Introduction

This exercise will demonstrate the methods used to clean two datasets `Water_cover` and `Land_cover`. Each dataset will be cleaned one at a time instead of simultaneously.

### Load libraries & Data

```{r}
# Load libraries
library(tidyverse)
library(here)

# Load data
snow_survey <- read_csv(here("data", "processed", "snow_cover.csv"))
```

### Water cover cleaning

Let's take a look at what kind of variable type we have for our `water_cover` column.

```{r}
# Use glimpse to view types
glimpse(snow_survey)
```

From using `glimpse` we can see that `Water_cover` is a type character. As these are supposed to be representing percentages, this is not good. Let's take a closer look to see why this might be happening.

```{r}
# Let's view all possible values for Water cover
snow_survey %>% 
  count(Water_cover)
```

From the exploration, it seems that there are `-` and `.` as values. Let's take a look at what columns will return an `NA` if they can't be converted to a numeric value. There may be more besides the two described above.

```{r}
# View non-numeric values in the column 
snow_survey %>% 
  count(Water_cover) %>% 
  filter(is.na(as.numeric(Water_cover)))
```

We do have more non-numeric values than we originally thought. Each of these unique values can be converted to an `NA` .

```{r}
# Convert non numerics to NAs
snow_survey_fixed <- snow_survey %>% 
  mutate(Water_cover = ifelse(Water_cover %in% c("-", ".", "n/a", "unk"), 
                              NA, Water_cover))
```

Now, let's test that we have only NAs as non-numeric values

```{r}
# View non-numerics to check the conversion worked
snow_survey_fixed %>% 
  count(Water_cover) %>% 
  filter(is.na(as.numeric(Water_cover)))
```

Everything looks great, so let's convert the column to a numeric.

```{r}
# Convert Water cover to numeric column 
snow_survey_fixed <- snow_survey_fixed %>% 
  mutate(Water_cover = as.numeric(Water_cover))
```

### Land Cover

Now that `Water_cover` is fixed, let's take a look at `Land_cover` . We will be using a very similar process to clean the data. Also, we will be using the `snow_survey_fixed` dataframe as it contains the cleaned `Water_cover` and `Snow_cover` columns. From the `glimpse` in the beginning we know that `Land_cover` is a character variable. Let's continue with a similar workflow as `Water_cover`.

```{r}
# View all non numeric values
snow_survey_fixed %>% 
  count(Land_cover) %>% 
  filter(is.na(as.numeric(Land_cover)))
```

We have the same non numeric values so we can use the same code as above.

```{r}
# Convert non numerics to NAs
snow_survey_fixed <- snow_survey_fixed %>% 
  mutate(Land_cover = ifelse(Land_cover %in% c("-", ".", "n/a", "unk"), 
                             NA, Water_cover))


# Check if NA is the only non-numeric value 
snow_survey_fixed %>% 
  count(Land_cover) %>% 
  filter(is.na(as.numeric(Land_cover)))
```

The non-numeric values have been successfully converted to `NA` values. We can now convert the column to numeric.

```{r}
# Convert Land cover to a numeric column
snow_survey_fixed <- snow_survey_fixed %>% 
  mutate(Land_cover = as.numeric(Land_cover))
```

### Total Cover

Now that these three columns are cleaned, let's recompute the total percentage with a new column called `Total_cover_recalc`. Since, we only have numeric percentages, when we recompute we should not have any non-numeric values besides `NA`. If values are present in any of the three columns, then the `Total_cover_recalc` will have a vale. If all three columns have an `NA`, then an `NA` will be computed for as the newly calculated value.

```{r}
# Recalculating Total cover
snow_survey_fixed <- snow_survey_fixed %>% 
  
  # Use rowwise to loop over each row
  rowwise() %>% 
  
  # Create new column for total cover
  mutate(
    
    # If all three columns have an NA, then total_cover_recalc = NA, else sum columns as expected 
    Total_cover_recalc = if (all(is.na(c(Snow_cover, Water_cover, Land_cover)))) {
      
      # NA value code
      NA_real_
      
      # ELSE...
    } else {
      sum(Snow_cover, Water_cover, Land_cover, na.rm = TRUE)
    }
  
  ) %>%
  
  # Ungroup for best practice
  ungroup()


# Check to see if total cover recalc has only NA non-numeric values
snow_survey_fixed %>% 
  count(Total_cover_recalc) %>% 
  filter(is.na(Total_cover_recalc))
```

### Comparing Total_cover and Total_cover_recalc

We are interested in comparing the original total cover and the newly calculated total cover column. This Let's view the rows that don't have the same values

```{r}
snow_survey_fixed %>% 
  filter(Total_cover != Total_cover_recalc) %>% 
  View()
```

From viewing this information, there are over 33,000 rows for these two columns that don't match. That is a huge number considering that our original data doesn't even have 43,000 rows. From just scrolling through this new dataframe, we can see that the values for original calculation of `Total_cover` are all over the place. It is safe to say that this column is unreliable and can be taken out.

```{r}
snow_survey_fixed <- snow_survey_fixed %>% 
  select(-Total_cover)
```

We are also interested in to see if any columns in our newly calculated total cover are greater than 100 and less than 0. We should technically only have values greater than or equal to 0 and less than or equal to 100 because they represent percentages.

```{r}

snow_survey_fixed %>% 
  
  # Filter for data over 100 OR less than 0 
  filter(Total_cover_recalc > 100 | Total_cover_recalc < 0) %>% 
  
  # Pipe into view
  View()
```

There are almost 4,600 rows that fit the criteria above. This is not good as that is about 10% of the entire dataframe. Since relational databases are strict with their rules I am going to filter out these rows since they are not good representations of a percentage.

```{r}
# Filter for only rows between 0 and 100
snow_survey_fixed <- snow_survey_fixed %>% 
  filter(Total_cover_recalc <= 100 & Total_cover_recalc >= 0 | is.na(Total_cover_recalc)) 

unique(snow_survey_fixed$Total_cover_recalc)
```

The above code will filter out rows that are outside those bounds and keeps rows that have `NA`.

### Output new df to a csv file

```{r}
# create path
datadir_processed <- file.path("data", "processed/")

# check if the folder exists
dir.create(datadir_processed, showWarnings = FALSE)

# write the file
write_csv(snow_survey_fixed, file.path(datadir_processed, "all_cover_fixed_Tom_Gibbens_Matsuyama.csv"))

```
